{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FLAML_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO631f38BwU1"
      },
      "source": [
        "# ***Installation***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhR793QTLwJ6",
        "outputId": "767df0a6-0dcc-4e43-8fdb-f13e419e38c4"
      },
      "source": [
        "!pip install flaml[notebook]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml[notebook] in /usr/local/lib/python3.7/dist-packages (0.6.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.90)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.4.1)\n",
            "Requirement already satisfied: catboost>=0.23 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.19.5)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (1.0.0)\n",
            "Requirement already satisfied: openml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (0.10.2)\n",
            "Requirement already satisfied: matplotlib==3.2.0 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.2.0)\n",
            "Requirement already satisfied: rgf-python in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]) (3.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.2.0->flaml[notebook]) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.23.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (2.5.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (1.1.5)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]) (0.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.23->flaml[notebook]) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->openml==0.10.2->flaml[notebook]) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]) (3.0.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (7.6.5)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.3.5)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]) (5.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->flaml[notebook]) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (1.0.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]) (5.1.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->flaml[notebook]) (4.8.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]) (2.11.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->flaml[notebook]) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->flaml[notebook]) (2.0.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]) (0.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (21.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]) (0.5.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.23->flaml[notebook]) (1.3.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->flaml[notebook]) (1.11.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMFpjEM1CU2P"
      },
      "source": [
        "# ***Importing Libraries and Dependencies***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXPstpyNHCBP"
      },
      "source": [
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import pandas as pd\n",
        "from flaml import AutoML\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt3n4dUEHGTH"
      },
      "source": [
        "# ***Data Loading***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQT44Oo6HKKD"
      },
      "source": [
        "X, y = sklearn.datasets.load_diabetes(return_X_y=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyh_k2Wd4mA_",
        "outputId": "31879d4f-4802-44af-ca5c-2a0124f2f1f4"
      },
      "source": [
        "X"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "         0.01990842, -0.01764613],\n",
              "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "        -0.06832974, -0.09220405],\n",
              "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "         0.00286377, -0.02593034],\n",
              "       ...,\n",
              "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "        -0.04687948,  0.01549073],\n",
              "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "         0.04452837, -0.02593034],\n",
              "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "        -0.00421986,  0.00306441]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI1YVJ664qKH",
        "outputId": "594c84f5-bdec-407c-edf7-56d2ddbd79e4"
      },
      "source": [
        "y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "       220.,  57.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbIP5dGDHrZJ"
      },
      "source": [
        "# ***Train Test Split***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9oNIG07HVcl"
      },
      "source": [
        "X_train, X_test, y_train, y_test = \\\n",
        "    sklearn.model_selection.train_test_split(X, y, random_state=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU9Bm1FiHxRl"
      },
      "source": [
        "# ***Initialize AutoML instance***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhtGth5WH6v2"
      },
      "source": [
        "# Initialize an AutoML instance\n",
        "automl = AutoML()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QBxqV3dIAAT"
      },
      "source": [
        "# ***Specify Settings***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksDZFHwFH_cm"
      },
      "source": [
        "automl_settings = {\n",
        "    \"time_budget\": 10,  # in seconds\n",
        "    \"metric\": 'r2',\n",
        "    \"task\": 'regression',\n",
        "    \"log_file_name\": \"diabetes.log\",\n",
        "}\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY-MXJXVIrsn"
      },
      "source": [
        "# ***Fit***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JCHUYHNIxoI",
        "outputId": "f71c3e1c-0d9c-40cd-eeef-247606467e43"
      },
      "source": [
        "'''The main flaml automl API'''\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 10-05 09:58:42] {1432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 10-05 09:58:42] {1478} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 10-05 09:58:42] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1866} INFO - Estimated sufficient time budget=229s. Estimated necessary time budget=0s.\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.7675,\tbest estimator lgbm's best error=0.7675\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.7675,\tbest estimator lgbm's best error=0.7675\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.6102,\tbest estimator lgbm's best error=0.6102\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.2s,\testimator xgboost's best error=2.4452,\tbest estimator lgbm's best error=0.6102\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.6102,\tbest estimator lgbm's best error=0.6102\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.6102,\tbest estimator lgbm's best error=0.6102\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:42] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.5989,\tbest estimator lgbm's best error=0.5989\n",
            "[flaml.automl: 10-05 09:58:42] {1748} INFO - iteration 7, current learner extra_tree\n",
            "[flaml.automl: 10-05 09:58:43] {1944} INFO -  at 1.5s,\testimator extra_tree's best error=0.6040,\tbest estimator lgbm's best error=0.5989\n",
            "[flaml.automl: 10-05 09:58:43] {1748} INFO - iteration 8, current learner rf\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.6s,\testimator rf's best error=0.6248,\tbest estimator lgbm's best error=0.5989\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.6s,\testimator lgbm's best error=0.5989,\tbest estimator lgbm's best error=0.5989\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.6s,\testimator lgbm's best error=0.5669,\tbest estimator lgbm's best error=0.5669\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.7s,\testimator lgbm's best error=0.5616,\tbest estimator lgbm's best error=0.5616\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.7s,\testimator lgbm's best error=0.5616,\tbest estimator lgbm's best error=0.5616\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.7s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.8s,\testimator xgboost's best error=2.4452,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.9347,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:44] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.6966,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:44] {1748} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.6966,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 32, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.2s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.3s,\testimator lgbm's best error=0.5332,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:45] {1944} INFO -  at 3.3s,\testimator xgboost's best error=0.5893,\tbest estimator lgbm's best error=0.5332\n",
            "[flaml.automl: 10-05 09:58:45] {1748} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.5s,\testimator extra_tree's best error=0.5266,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.5s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.5s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.5s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.6s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:46] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:46] {1748} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.8s,\testimator extra_tree's best error=0.5266,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.8s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.8s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.9s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.9s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:47] {1944} INFO -  at 5.9s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:47] {1748} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.1s,\testimator extra_tree's best error=0.5266,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.2s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.2s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.3s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.3s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.3s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 56, current learner catboost\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.8s,\testimator catboost's best error=0.5541,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:49] {1944} INFO -  at 7.9s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:49] {1748} INFO - iteration 58, current learner rf\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.0s,\testimator rf's best error=0.5559,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 59, current learner catboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.3s,\testimator catboost's best error=0.5541,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 60, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.3s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 62, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.4s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 65, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.5s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 66, current learner catboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.7s,\testimator catboost's best error=0.5541,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.7s,\testimator xgboost's best error=0.5893,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.7s,\testimator xgboost's best error=0.5798,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 70, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 71, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.8s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 72, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.9s,\testimator xgboost's best error=0.5798,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 74, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:51] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:51] {1748} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:52] {1944} INFO -  at 9.9s,\testimator xgboost's best error=0.5798,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:52] {1748} INFO - iteration 76, current learner lgbm\n",
            "[flaml.automl: 10-05 09:58:52] {1944} INFO -  at 10.0s,\testimator lgbm's best error=0.5332,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:52] {1748} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 10-05 09:58:52] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.5798,\tbest estimator extra_tree's best error=0.5266\n",
            "[flaml.automl: 10-05 09:58:52] {2043} INFO - selected model: ExtraTreesRegressor(max_features=0.9586055955836026, max_leaf_nodes=9,\n",
            "                    n_estimators=4, n_jobs=-1)\n",
            "[flaml.automl: 10-05 09:58:52] {2106} INFO - retrain extra_tree for 0.2s\n",
            "[flaml.automl: 10-05 09:58:52] {2110} INFO - retrained model: ExtraTreesRegressor(max_features=0.9586055955836026, max_leaf_nodes=9,\n",
            "                    n_estimators=4, n_jobs=-1)\n",
            "[flaml.automl: 10-05 09:58:52] {1539} INFO - fit succeeded\n",
            "[flaml.automl: 10-05 09:58:52] {1541} INFO - Time taken to find the best model: 4.456122159957886\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADv0h266I3N9"
      },
      "source": [
        "# ***Statistics***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLWtNcBCJ91z",
        "outputId": "1562aeef-f58b-4ccb-e704-5f04848c64be"
      },
      "source": [
        "''' retrieve best config and best learner'''\n",
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: extra_tree\n",
            "Best hyperparmeter config: {'n_estimators': 4, 'max_features': 0.9586055955836026, 'max_leaves': 9}\n",
            "Best accuracy on validation data: 0.4734\n",
            "Training duration of best run: 1.133 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUXhG-f_xUvI",
        "outputId": "fa9bce37-2f1c-4759-ed5f-36b596cc5a6a"
      },
      "source": [
        "automl.model.estimator"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ExtraTreesRegressor(max_features=0.9586055955836026, max_leaf_nodes=9,\n",
              "                    n_estimators=4, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myPmDCyOI_1h"
      },
      "source": [
        "# ***Saving Model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7grCGiNiKXSA"
      },
      "source": [
        "''' pickle and save the automl object '''\n",
        "import pickle\n",
        "with open('automl_diabetes.pkl', 'wb') as f:\n",
        "    pickle.dump(automl, f, pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qmKD0L12ZZa"
      },
      "source": [
        "# ***Predictions***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Cqb8yT2bta",
        "outputId": "83e085fe-da91-4a3f-f798-b6a471161ee6"
      },
      "source": [
        "''' compute predictions of testing dataset ''' \n",
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels [155.22274152 104.32930054 159.42323579 104.32930054 169.39298065\n",
            " 212.71803314 254.26025017 110.59195883 126.59664204 107.27274549\n",
            " 198.92453231 178.45804663 113.53239622 104.32930054 223.41995621\n",
            " 195.27376787 169.15873186 106.27815674 131.31261583 191.75275641\n",
            " 169.39298065  99.37822167 108.64310262 105.32388928 104.32930054\n",
            " 174.32045415  99.37822167 153.18503912 132.30720458 185.13499742\n",
            " 156.55491875 185.22226107 222.06655554 104.32930054 147.13304244\n",
            " 212.71803314 112.77010741 235.86005637 186.18836305 178.45804663\n",
            " 151.67454631 161.48239225 113.53239622 116.53762644 140.94599185\n",
            " 178.45804663 137.96575887 117.84612444 214.408416   178.45804663\n",
            "  99.37822167 118.74111849 113.53239622 153.27388531 212.71803314\n",
            " 118.57550523 167.14867826 112.62983762  99.37822167  99.37822167\n",
            " 129.4585949  234.05472132 160.36991668 120.85980649 254.26025017\n",
            "  99.37822167 107.81902854 181.38443824 181.33122746  99.37822167\n",
            " 168.95444086 107.81902854 107.81902854 122.79727718 177.02140443\n",
            " 130.06290218 115.5430377  107.81902854 169.84049282 116.85160956\n",
            " 130.06290218 105.32388928 115.5430377  158.86299956 113.53239622\n",
            " 118.57550523 104.32930054 104.32930054 217.03130978 131.31261583\n",
            " 185.22226107 168.45961576 112.77010741 114.71896362 113.59418149\n",
            " 149.86697415 114.71896362 131.31261583 129.64375986 138.9410396\n",
            " 104.32930054  99.37822167 106.27815674 178.45804663 254.26025017\n",
            " 131.12800787 178.45804663 235.86005637 143.19029425 104.32930054\n",
            " 132.30720458]\n",
            "True labels [ 78. 152. 200.  59. 311. 178. 332. 132. 156. 135. 220. 233.  91.  51.\n",
            " 195. 109. 217.  94.  89. 111. 129. 181. 168.  97. 115. 202.  84. 147.\n",
            " 253. 144. 262. 115.  68.  65. 252. 212. 142. 215. 180. 163. 151. 283.\n",
            "  66.  83. 214. 189. 302.  93. 178. 241.  52. 144. 102. 200. 232.  97.\n",
            " 109.  55.  63.  98.  88. 233. 235.  97. 243.  59. 138. 220. 137.  72.\n",
            " 109.  71.  74. 219. 196. 170. 199.  71. 155.  52.  63.  88.  97. 100.\n",
            "  64. 107.  49.  60. 346. 104. 259. 143. 190. 104.  77. 141. 214.  51.\n",
            " 175. 167.  90.  39. 160. 101. 180.  69. 281. 281. 214.  96. 146.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CecUtSN2z7I",
        "outputId": "29e4d145-a975-49e9-f3ef-4245352f1358"
      },
      "source": [
        "\n",
        "from sklearn.metrics import max_error, mean_absolute_error,mean_squared_log_error, mean_squared_error, r2_score\n",
        "print('max error value :',max_error(y_test,y_pred))\n",
        "print('mean absolute error value :',mean_absolute_error(y_test,y_pred))\n",
        "print('mean squared error :', mean_squared_error(y_test,y_pred))\n",
        "print(\"mean squared log error :\", mean_squared_log_error(y_test,y_pred))\n",
        "print(\"r2 score :\" ,r2_score(y_test,y_pred)) "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max error value : 164.03424113119144\n",
            "mean absolute error value : 46.99704328494246\n",
            "mean squared error : 3349.384128944348\n",
            "mean squared log error : 0.17264778323577365\n",
            "r2 score : 0.3584980832443341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBdd_uPI28hh"
      },
      "source": [
        "# ***Log History***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZROMy8ek2_ss",
        "outputId": "ecfb0cca-fcc6-4ed3-8015-6d294214fd6e"
      },
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=automl_settings['log_file_name'], time_budget=240)\n",
        "for config in config_history:\n",
        "    print(config)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 12, 'learning_rate': 0.26770501231052046, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.001348364934537134, 'reg_lambda': 1.4442580148221913}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 7, 'learning_rate': 0.2798674441105101, 'log_max_bin': 6, 'colsample_bytree': 0.9019070144825116, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09189114905095784}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 7, 'learning_rate': 0.2798674441105101, 'log_max_bin': 6, 'colsample_bytree': 0.9019070144825116, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09189114905095784}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.5066472382072831, 'log_max_bin': 6, 'colsample_bytree': 0.9712608239851066, 'reg_alpha': 0.008673969948933881, 'reg_lambda': 0.47452813352268625}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 9, 'learning_rate': 0.5066472382072831, 'log_max_bin': 6, 'colsample_bytree': 0.9712608239851066, 'reg_alpha': 0.008673969948933881, 'reg_lambda': 0.47452813352268625}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 7, 'learning_rate': 0.2798674441105101, 'log_max_bin': 6, 'colsample_bytree': 0.9019070144825116, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09189114905095784}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 8, 'num_leaves': 4, 'min_child_samples': 7, 'learning_rate': 0.2798674441105101, 'log_max_bin': 6, 'colsample_bytree': 0.9019070144825116, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.09189114905095784}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 15, 'num_leaves': 9, 'min_child_samples': 6, 'learning_rate': 0.11615513596984775, 'log_max_bin': 6, 'colsample_bytree': 0.8057683870789988, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06694671490087994}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 15, 'num_leaves': 9, 'min_child_samples': 6, 'learning_rate': 0.11615513596984775, 'log_max_bin': 6, 'colsample_bytree': 0.8057683870789988, 'reg_alpha': 0.0009765625, 'reg_lambda': 0.06694671490087994}}\n",
            "{'Current Learner': 'extra', 'Current Sample': 331, 'Current Hyper-parameters': {'n_estimators': 4, 'max_features': 0.9586055955836026, 'max_leaves': 9}, 'Best Learner': 'extra', 'Best Hyper-parameters': {'n_estimators': 4, 'max_features': 0.9586055955836026, 'max_leaves': 9}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM3a_i-l3kF5"
      },
      "source": [
        "# ***Learning Curve***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-r8xbcAa3nJB",
        "outputId": "a9907532-aaed-4835-d539-64fab37b20ab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}